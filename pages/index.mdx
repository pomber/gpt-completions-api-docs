<CH.Scrollycoding>

# OpenAI Chat Completion <br/> Unofficial Docs

_This is a work in progress. If you want to contribute, here is the [GitHub repo](https://github.com/pomber/gpt-completions-api-docs)._

This site offers an alternative take on the [official API reference](https://beta.openai.com/docs/api-reference/chat) and the [official GPT guide](https://platform.openai.com/docs/guides/gpt).

In its most basic form, the Chat Completion API receives a _`system`_ message (the prompt) and a _`user`_ message, and then returns an _`assistant`_ message responding to the user.

```js focus=9:12,17:20 mark=11[30:42],19[14:49]
// from ../snippets/start.js
```

In this example, we are using the OpenAI node library, but the focus of this guide will be the request and response format, which is the same for the python library and the HTTP API.

---

## Request and Response

```js focus=7[54],8:24,25[1],28[30],29:47,48[1]
// from ../snippets/base.js
```

Both the request and the response have lots of fields. Most are optional, some are required. Some only make sense in combination with others.

**If you are interested in a particular field, you can click on it to jump to the section that describes it.**

---

## API key

<nav id="api-key" />

```js focus=3
// from ../snippets/base.js
```

The first thing you'll need is the _`OPENAI_API_KEY`_. Visit your [API Keys](https://platform.openai.com/account/api-keys) page to retrieve the API key you'll use in your requests.

**Remember that your API key is a secret!** Do not share it with others or expose it in any client-side code (browsers, apps). Production requests must be routed through your own backend server where your API key can be securely loaded from an environment variable or key management service.

---

## Model

<nav id="model" />

```js focus=8
// from ../snippets/base.js
```

_`model`_ is a required field.

It should be one of:

- `gpt-3.5-turbo`
- `gpt-3.5-turbo-0613`
- `gpt-3.5-turbo-16k`
- `gpt-3.5-turbo-16k-0613`
- `gpt-4`
- `gpt-4-0613`
- `gpt-4-32k`
- `gpt-4-32k-0613`

If you don't know which one to use, start with `gpt-3.5-turbo`.

June 27th, 2023 from gpt-4-0314 to gpt-4-0613

`gpt-3.5-turbo` models are cheaper and faster.

`gpt-4` models have broader general knowledge and advanced reasoning. But they are more expensive, slower, and you need to [ask for access](https://openai.com/waitlist/gpt-4-api) to use them.

---

## Messages

<nav id="messages" />

```js focus=9:12
// from ../snippets/base.js
```

_`messages`_ is a required array. A list of messages comprising the conversation so far.

Each message follows the format:

```js
{
  role: "system" | "user" | "assistant" | "function",
  content: string | undefined,
  name: string | undefined,
  function_call: object | undefined,
}
```

The first message in the array is the prompt. And it's the only message with _`role: "system"`_.

---

## Assistant

<nav id="assistant" />

```js focus=9:14,38:41 mark=12[13:23]
// from ../snippets/assistant.js
```

As you make subsequent requests, you should add the _`assistant`_ message from the response to the _`messages`_ array. This way, the model will have more context about the conversation.

You can also send _`assistant`_ messages on the first request. This is useful to give the model examples of desired behavior.

---

## Functions

<nav id="functions" />

```js focus=13:29
// from ../snippets/functions.js
```

An optional list of functions the model may generate JSON inputs for.

The latest models (`gpt-3.5-turbo-0613` and `gpt-4-0613`) have been fine-tuned to both detect when a function should to be called (depending on the input) and to respond with JSON that adheres to the function signature. With this capability also comes potential risks. We strongly recommend building in user confirmation flows before taking actions that impact the world on behalf of users (sending an email, posting something online, making a purchase, etc).

---

## Parameters

<nav id="parameters" />

```js focus=17:26
// from ../snippets/functions.js
```

The parameters the functions accepts, described as a JSON Schema object. See the [JSON Schema reference](https://json-schema.org/understanding-json-schema/) for documentation about the format.

---

## Function Call

<nav id="function-call" />

```js focus=30,50:58
// from ../snippets/functions.js
```

Controls how the model responds to function calls. "none" means the model does not call a function and responds to the end-user. `"auto"` means the model can pick between an end-user or calling a function. Specifying a particular function via _`{"name": "my_function"}`_ forces the model to call that function.

`"none"` is the default when no functions are present. `"auto"` is the default if functions are present.

---

## User

<nav id="user" />

---

## Stream

<nav id="stream" />

---

## Sampling

<nav id="sampling" />

```js focus=17
// from ../snippets/base.js
```

Controls the randomness of the model's output. This parameter is a decimal value typically ranging from _`0`_ to _`1`_. A lower temperature (_`0.1`_ or _`0.2`_) makes the output more deterministic and focused, with the model likely to choose only the most probable word at each step.

A higher temperature (_`0.8`_ or _`1`_) makes the output more diverse and random, taking more chances in its choices of words.

---

## Choices

<nav id="choices" />

---

## Stop

<nav id="stop" />

---

## Max Tokens

<nav id="max-tokens" />

---

## Penalties

<nav id="penalties" />

---

## Logit Bias

<nav id="logit-bias" />

---

## Response

<nav id="response" />

---

## Finish Reason

<nav id="finish-reason" />

Every response will include a `finish_reason`. The possible values for `finish_reason` are:

- `stop`: API returned complete message, or a message terminated by one of the stop sequences provided via the [stop](https://platform.openai.com/docs/api-reference/chat/create#chat/create-stop) parameter
- `length`: Incomplete model output due to [`max_tokens`](https://platform.openai.com/docs/api-reference/chat/create#chat/create-max_tokens) parameter or token limit
- `function_call`: The model decided to call a function
- `content_filter`: Omitted content due to a flag from our content filters
- `null`: API response still in progress or incomplete

---

## Usage

<nav id="usage" />

TODO: find somewhere to put the github link

[GitHub](https://github.com/pomber/gpt-completions-api-docs)

</CH.Scrollycoding>
